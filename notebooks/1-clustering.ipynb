{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "placed-device",
   "metadata": {},
   "source": [
    "# Clustering from SafeGraph data\n",
    "\n",
    "[Index](0-index.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-coordinator",
   "metadata": {},
   "source": [
    "## Imports and global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-guyana",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-introduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import datetime\n",
    "import h5py\n",
    "import scipy\n",
    "import sklearn.cluster\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mco\n",
    "import matplotlib.gridspec as mgs\n",
    "import matplotlib.cm as cm\n",
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "import scipy.cluster.hierarchy as sch\n",
    "\n",
    "\n",
    "from IPython.display import HTML\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-basin",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = Path('../data')\n",
    "if not datadir.is_dir():\n",
    "    raise ValueError(\"Data dir doesn'nt exist!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-train",
   "metadata": {},
   "outputs": [],
   "source": [
    "resdir = Path('../results/')\n",
    "if not resdir.is_dir():\n",
    "    raise ValueError('No results directory!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broke-incident",
   "metadata": {},
   "outputs": [],
   "source": [
    "resfile_init = datadir / 'safegraph_analysis_start.hdf5'\n",
    "resfile = resdir / 'safegraph_analysis.hdf5'\n",
    "shutil.copy(resfile_init, resfile)\n",
    "\n",
    "complevel=7\n",
    "complib='zlib'\n",
    "with pd.HDFStore(resfile, complevel=complevel, complib=complib) as store:\n",
    "    print(f\"File {resfile.stem} has {len(store.keys())} entries.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e365ad-7c06-456e-82b2-dd5c8f54e65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "exts = ['.png', '.svg']\n",
    "dpi=300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perceived-package",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chronic-client",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dict_serializable(mydict):\n",
    "    for k, v in mydict.items():\n",
    "        if isinstance(v, dict):\n",
    "            make_dict_serializable(v)\n",
    "        else:\n",
    "            if type(v) == np.ndarray:\n",
    "                mydict[k]= v.tolist()                                      \n",
    "            elif type(v) == pd.Int64Index:\n",
    "                mydict[k]=v.tolist()\n",
    "            elif type(v) == np.float_:\n",
    "                mydict[k]=float(v)\n",
    "            elif type(v) == np.int_:\n",
    "                mydict[k]=int(v)\n",
    "            elif type(v) == datetime.datetime:\n",
    "                mydict[k]=v.strftime('%Y-%m-%d')\n",
    "    return mydict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "computational-portfolio",
   "metadata": {},
   "source": [
    "## Construct index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-shell",
   "metadata": {},
   "outputs": [],
   "source": [
    "geofile = datadir / 'geometry' / 'cbg.geojson'\n",
    "if not geofile.is_file():\n",
    "    raise ValueError(\"Geo file doesn't exist!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ruled-penny",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo = gpd.read_file(geofile).astype({'CensusBlockGroup': 'int64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesser-wedding",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo.set_index('CensusBlockGroup', inplace=True)\n",
    "geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a191e516-e474-486c-8e0b-9478d00d837b",
   "metadata": {},
   "outputs": [],
   "source": [
    "figdir = Path('..') / 'figures' / '1-clustering'\n",
    "if not figdir.is_dir():\n",
    "    figdir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patent-sauce",
   "metadata": {},
   "outputs": [],
   "source": [
    "XY = geo.representative_point()\n",
    "indices = np.arange(len(geo.index))\n",
    "XY = np.array([[x.x,x.y] for x in XY.to_numpy()])\n",
    "X,Y = XY.T\n",
    "\n",
    "norm = mco.Normalize(vmin=np.min(indices), vmax=np.max(indices))\n",
    "cmap = cm.rainbow\n",
    "\n",
    "colors = cmap(norm(indices))\n",
    "\n",
    "fig = plt.figure(figsize=(4,3),dpi=300)\n",
    "ax = fig.gca()\n",
    "npts = len(X)\n",
    "idump = 5\n",
    "for i in np.arange(npts)[::idump]:\n",
    "#     if i % idump == 0:\n",
    "#         print(f\"{i} / {npts}\")\n",
    "    x = X[i]\n",
    "    y = Y[i]\n",
    "    circle = plt.Circle((x,y), 0.5, color=colors[i], alpha=0.5, lw=0)\n",
    "    ax.add_patch(circle)\n",
    "    \n",
    "xmin = np.min(X)\n",
    "xmax = np.max(X)\n",
    "ymin = np.min(Y)\n",
    "ymax = np.max(Y)\n",
    "ax.set_xlim(xmin, xmax)\n",
    "ax.set_ylim(ymin, ymax)\n",
    "ax.set_aspect('equal')\n",
    "for lab in 'left', 'right', 'bottom', 'top':\n",
    "    ax.spines[lab].set_visible(False)\n",
    "ax.tick_params(bottom=False, left=False, labelbottom=False, labelleft=False)\n",
    "cax = fig.add_axes(rect=[0.98,0.1,0.02,0.7])\n",
    "plt.colorbar(cm.ScalarMappable(norm=norm, cmap=cmap),\n",
    "             cax=cax, label='Matrix index', extendfrac='auto')\n",
    "\n",
    "fname = 'clusters_before_ordering'\n",
    "for ext in exts:\n",
    "    filepath = figdir / (fname + ext)\n",
    "    fig.savefig(filepath, bbox_inches='tight', pad_inches=0, dpi=dpi)\n",
    "    print(\"Written file: {:s}\".format(str(filepath)))\n",
    "fig.clf()\n",
    "plt.close('all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35abed61-3839-4180-a708-1c947b1160ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'clusters_before_ordering'\n",
    "filepath = figdir / (fname + '.png')\n",
    "Image(filename=filepath, width=4./3*360)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "egyptian-guide",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "characteristic-wilderness",
   "metadata": {},
   "source": [
    "### K-means clustering -- KMeans()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-possible",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNCOMMENT TO RECOMPUTE\n",
    "# n_clusters = 2**10\n",
    "# np.random.seed(123)\n",
    "\n",
    "# clustering = sklearn.cluster.KMeans(n_clusters=n_clusters, algorithm=\"full\")\n",
    "# res = clustering.fit(XY)\n",
    "\n",
    "# cluster_centers = res.cluster_centers_\n",
    "# data_labels = res.predict(XY)\n",
    "# data_labels = pd.DataFrame(data_labels, index=geo.index)\n",
    "# data_labels.rename(columns={0: 'leaves'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-youth",
   "metadata": {},
   "source": [
    "### Re-order clusters using a hierarchichal clustering method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cordless-harvard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNCOMMENT TO RECOMPUTE\n",
    "# XY = cluster_centers.copy()\n",
    "# Z = sch.linkage(XY, method='average')\n",
    "# Z = sch.optimal_leaf_ordering(Z, XY)\n",
    "\n",
    "# key_base = Path(\"/clustering\")\n",
    "# with pd.HDFStore(resfile, complevel=complevel, complib=complib) as store:\n",
    "#     key = str(key_base / \"cbgs_clusters\")\n",
    "#     store[key] = data_labels\n",
    "    \n",
    "#     key = str(key_base / \"linkage_matrix\")\n",
    "#     store[key] = pd.DataFrame(data=Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMENT TO RECOMPUTE\n",
    "key_base = Path(\"/clustering\")\n",
    "with pd.HDFStore(resfile, complevel=complevel, complib=complib) as store:\n",
    "    key = str(key_base / \"cbgs_clusters\")\n",
    "    data_labels = store[key]\n",
    "    \n",
    "    key = str(key_base / \"linkage_matrix\")\n",
    "    Z = store[key].to_numpy()\n",
    "    \n",
    "    key = str(key_base / \"clusters\")\n",
    "    cluster_centers = store[key].set_index('leaves').sort_index(axis=0).loc[:,['X','Y']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-motion",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaves = sch.leaves_list(Z).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-lying",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,4))\n",
    "ax = fig.gca()\n",
    "dendrogram(Z, truncate_mode='level', p=6, ax=ax, show_leaf_counts=False)\n",
    "plt.xticks(rotation=90, fontsize='medium')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "severe-number",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_centers_ordered = cluster_centers[leaves]\n",
    "X,Y = cluster_centers_ordered.T\n",
    "npts = len(X)\n",
    "indices = np.arange(npts)\n",
    "\n",
    "norm = mco.Normalize(vmin=np.min(indices), vmax=np.max(indices))\n",
    "cmap = cm.rainbow\n",
    "\n",
    "colors = cmap(norm(indices))\n",
    "\n",
    "fig = plt.figure(figsize=(4,3),dpi=300)\n",
    "ax = fig.gca()\n",
    "for i in np.arange(npts):\n",
    "#     if i % idump == 0:\n",
    "#         print(f\"{i} / {npts}\")\n",
    "    x = X[i]\n",
    "    y = Y[i]\n",
    "    circle = plt.Circle((x,y), 0.5, color=colors[i], alpha=0.5, lw=0)\n",
    "    ax.add_patch(circle)\n",
    "    \n",
    "xmin = np.min(X)\n",
    "xmax = np.max(X)\n",
    "ymin = np.min(Y)\n",
    "ymax = np.max(Y)\n",
    "ax.set_xlim(xmin, xmax)\n",
    "ax.set_ylim(ymin, ymax)\n",
    "ax.set_aspect('equal')\n",
    "for lab in 'left', 'right', 'bottom', 'top':\n",
    "    ax.spines[lab].set_visible(False)\n",
    "ax.tick_params(bottom=False, left=False, labelbottom=False, labelleft=False)\n",
    "cax = fig.add_axes(rect=[0.98,0.1,0.02,0.7])\n",
    "plt.colorbar(cm.ScalarMappable(norm=norm, cmap=cmap),\n",
    "             cax=cax, label='Matrix index', extendfrac='auto')\n",
    "\n",
    "fname = 'clusters_after_ordering'\n",
    "for ext in exts:\n",
    "    filepath = figdir / (fname + ext)\n",
    "    fig.savefig(filepath, bbox_inches='tight', pad_inches=0, dpi=dpi)\n",
    "    print(\"Written file: {:s}\".format(str(filepath)))\n",
    "fig.clf()\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0253cc27-7c9e-4e4c-9387-2bccfaa1b441",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'clusters_after_ordering'\n",
    "filepath = figdir / (fname + '.png')\n",
    "Image(filename=filepath, width=4./3*360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balanced-spectacular",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = data_labels.groupby(['leaves']).groups\n",
    "groups = [groups[i].tolist() for i in range(len(cluster_centers))]\n",
    "groups_ordered = [groups[leaves[i]] for i in range(len(leaves))]\n",
    "\n",
    "df = pd.DataFrame(data=cluster_centers_ordered, columns=['X', 'Y'])\n",
    "df = pd.concat([df, pd.DataFrame(pd.Series(groups_ordered), columns=['cbg_clusters'])], axis=1)\n",
    "df = pd.concat([df, pd.DataFrame(pd.Series(leaves), columns=['leaves'])], axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respective-underwear",
   "metadata": {},
   "source": [
    "### Fill-in total population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-optics",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['B01001e1']\n",
    "cbg_data = pd.read_csv(datadir 'safegraph_open_census_data' / 'data' / 'cbg_b01.csv').set_index('census_block_group').loc[:,columns]\n",
    "cbg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "julian-kruger",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labels['population']= cbg_data.loc[data_labels.index]\n",
    "data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valid-saint",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = data_labels.groupby(by='leaves')['population'].sum().to_frame()\n",
    "pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "institutional-filter",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)\n",
    "df.set_index('leaves', inplace=True)\n",
    "df.loc[pop.index,'population'] = pop['population']\n",
    "df.reset_index(inplace=True)\n",
    "df.set_index('index', inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capital-electron",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['population'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "killing-guinea",
   "metadata": {},
   "source": [
    "So there is one empty community once the CBGs are clustered using SafeGraph data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "established-certification",
   "metadata": {},
   "source": [
    "### Write final clustering information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-aircraft",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_base = Path(\"/clustering\")\n",
    "with pd.HDFStore(resfile, complevel=complevel, complib=complib) as store:\n",
    "    key = str(key_base / \"clusters\")\n",
    "    store[key] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20178c97-d245-4894-9682-7c809f9511c1",
   "metadata": {},
   "source": [
    "Export to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecaf3576-44c5-4a45-a7e1-13fa26882974",
   "metadata": {},
   "outputs": [],
   "source": [
    "expdir = resdir / 'csv'\n",
    "if not expdir.is_dir():\n",
    "    expdir.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6de31f-3a08-4b49-a661-7bb39ffbb784",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'clustering.csv'\n",
    "df.to_csv(expdir / fname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
