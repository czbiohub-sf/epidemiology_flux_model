{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "frank-germany",
   "metadata": {},
   "source": [
    "# Processing of the flux matrices\n",
    "[Index](0-index.ipynb)\n",
    "\n",
    "Flux matrices were computed using the SafeGraph [Social Distancing Metrics](https://docs.safegraph.com/docs/social-distancing-metrics) dataset and pooling the fluxes in $N=2^{10}$ communities as computed in [1-clustering](1-clustering.ipynb). The script used is shown [here](../code/compute_flux_matrices.py), although we do not provide the SafeGraph dataset here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "significant-portable",
   "metadata": {},
   "source": [
    "## Imports and global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bizarre-myanmar",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driving-robinson",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import datetime\n",
    "import scipy.stats as scs\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mco\n",
    "import matplotlib.gridspec as mgs\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import animation\n",
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "private-catalog",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../code')\n",
    "from functions import show_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjustable-favor",
   "metadata": {},
   "outputs": [],
   "source": [
    "resdir = Path('../results/')\n",
    "if not resdir.is_dir():\n",
    "    raise ValueError('No results directory!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-calibration",
   "metadata": {},
   "outputs": [],
   "source": [
    "resfile = resdir / 'safegraph_analysis.hdf5'\n",
    "complevel=7\n",
    "complib='zlib'\n",
    "with pd.HDFStore(resfile, complevel=complevel, complib=complib) as store:\n",
    "    print(f\"File {resfile.stem} has {len(store.keys())} entries.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-december",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfmt = '%Y-%m-%d'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "australian-double",
   "metadata": {},
   "source": [
    "## Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "productive-workplace",
   "metadata": {},
   "source": [
    "### Load clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hispanic-yesterday",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"/clustering/clusters\"\n",
    "with pd.HDFStore(resfile, complevel=complevel, complib=complib) as store:\n",
    "    clusters = store[key]\n",
    "# clusters = pd.read_hdf(resfile, key)\n",
    "N = len(clusters)\n",
    "print(f\"N = {N}\")\n",
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "private-explosion",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"/clustering/cbgs_clusters\"\n",
    "with pd.HDFStore(resfile, complevel=complevel, complib=complib) as store:\n",
    "    cbgs_labels = store[key]\n",
    "\n",
    "df = clusters.copy().loc[:,'leaves'].reset_index().set_index('leaves')\n",
    "cbgs_labels['index'] = -1\n",
    "\n",
    "for cbgs in cbgs_labels.index:\n",
    "    cbgs_labels.at[cbgs, 'index'] = df.at[cbgs_labels.at[cbgs, 'leaves'],'index']\n",
    "\n",
    "cbgs_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-international",
   "metadata": {},
   "source": [
    "### Represent on a map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-reputation",
   "metadata": {},
   "outputs": [],
   "source": [
    "XY = clusters.loc[:, ['X', 'Y']].to_numpy()\n",
    "indices = clusters.index.to_numpy()\n",
    "X,Y = XY.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "massive-feeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = mco.Normalize(vmin=np.min(indices), vmax=np.max(indices))\n",
    "cmap = cm.rainbow\n",
    "\n",
    "colors = cmap(norm(indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominant-vulnerability",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4,3),dpi=300)\n",
    "ax = fig.gca()\n",
    "for i in range(len(X)):\n",
    "    x = X[i]\n",
    "    y = Y[i]\n",
    "    circle = plt.Circle((x,y), 0.5, color=colors[i], alpha=0.5, lw=0)\n",
    "    ax.add_patch(circle)\n",
    "    \n",
    "xmin = np.min(X)\n",
    "xmax = np.max(X)\n",
    "ymin = np.min(Y)\n",
    "ymax = np.max(Y)\n",
    "ax.set_xlim(xmin, xmax)\n",
    "ax.set_ylim(ymin, ymax)\n",
    "ax.set_aspect('equal')\n",
    "for lab in 'left', 'right', 'bottom', 'top':\n",
    "    ax.spines[lab].set_visible(False)\n",
    "ax.tick_params(bottom=False, left=False, labelbottom=False, labelleft=False)\n",
    "cax = fig.add_axes(rect=[0.98,0.1,0.02,0.7])\n",
    "plt.colorbar(cm.ScalarMappable(norm=norm, cmap=cmap),\n",
    "             cax=cax, label='Matrix index', extendfrac='auto')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detected-ground",
   "metadata": {},
   "source": [
    "## Process flux matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "widespread-insulin",
   "metadata": {},
   "source": [
    "### List the entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "together-topic",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore(resfile, complevel=complevel, complib=complib) as store:\n",
    "    for rt, grps, keys in store.walk('/fluxes'):\n",
    "        pass\n",
    "prefs = [k for k in keys]\n",
    "print(\"len(prefs) = {:d}\".format(len(prefs)))\n",
    "# prefs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternative-methodology",
   "metadata": {},
   "source": [
    "### Compute and show mean matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "permanent-wright",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(clusters)\n",
    "fmat_mean = np.zeros((N,N), dtype=np.float_)\n",
    "fmat_var = np.zeros((N,N), dtype=np.float_)\n",
    "\n",
    "count = 0\n",
    "for i, pref in enumerate(prefs):\n",
    "    # define all store keys\n",
    "    key_f = \"/fluxes/{:s}\".format(pref)    \n",
    "#     print(f\"File {i+1} / {len(prefs)}\", key_f)\n",
    "    \n",
    "    with pd.HDFStore(resfile, complevel=complevel, complib=complib) as store:            \n",
    "        F = store[key_f].to_numpy()\n",
    "        \n",
    "    # average\n",
    "    fmat_mean += F\n",
    "    fmat_var += F**2\n",
    "    count += 1\n",
    "\n",
    "fmat_mean = fmat_mean / count\n",
    "fmat_var = fmat_var / count - fmat_mean**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-realtor",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = show_image(fmat_mean, downscale=None, log=True, mpl=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-headquarters",
   "metadata": {},
   "source": [
    "Check that $\\sum_\\limits{b} f_{ba} / M_a$ is small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d8e83b-8230-4be5-b656-0c1250c02e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ms = fmat_mean.diagonal()\n",
    "idx = Ms > 0.\n",
    "Minvs = np.zeros(Ms.shape)\n",
    "Minvs[idx] = 1./Ms[idx]\n",
    "A = fmat_mean.copy()\n",
    "np.fill_diagonal(A, 0.)\n",
    "A = np.einsum('ji,i->i', A, Minvs)\n",
    "err = np.sum(A[idx]**2 / len(A))\n",
    "print(\"std = {:.6e}\".format(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabulous-optics",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = fmat_mean.T / np.diag(fmat_mean) - np.eye(N)\n",
    "A[~np.isfinite(A)] = 0.\n",
    "idx = A > 0.\n",
    "M = np.sum(idx)\n",
    "np.sqrt(np.sum(A[idx]**2/M))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olive-fleet",
   "metadata": {},
   "source": [
    "$\\| F - F^T\\| / \\|F\\|$ is small so the mean flux matrix is almost symmetric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broad-logistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.linalg.norm(fmat_mean)\n",
    "err = np.linalg.norm(fmat_mean - fmat_mean.T)\n",
    "err_rel = err/f\n",
    "print(\"||F|| = {:.6e}\".format(f), \"||F - F^T|| = {:.6e}\".format(err), \"||F - F^T||/||F|| = {:.6e}\".format(err_rel))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dated-cologne",
   "metadata": {},
   "source": [
    "We can also represent the variance of the mean fluxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrapped-first",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = show_image(fmat_var, downscale=None, log=True, mpl=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb6626e-4b30-4569-83d5-b10281a2ebf3",
   "metadata": {},
   "source": [
    "Export mean flux matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca13774-8e45-4c2c-bc3f-92cf7149deb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "expdir = resdir / 'csv'\n",
    "if not expdir.is_dir():\n",
    "    expdir.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc46139d-3edd-492b-b52e-5710a4aa46e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'fluxes_mean.csv'\n",
    "pd.DataFrame(data=fmat_mean, index=clusters.index.to_numpy(), columns=clusters.index.to_numpy()).to_csv(expdir / fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continued-dragon",
   "metadata": {},
   "source": [
    "### What is the noise distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-zambia",
   "metadata": {},
   "outputs": [],
   "source": [
    "mats = []\n",
    "with pd.HDFStore(resfile, complevel=complevel, complib=complib) as store:\n",
    "    for pref in prefs:\n",
    "        key_f = \"/fluxes/{:s}\".format(pref)\n",
    "        mat = store[key_f].to_numpy()\n",
    "        mats.append(mat)\n",
    "mats = np.array(mats, dtype=np.float_)\n",
    "mats.shape\n",
    "\n",
    "mat_mean = np.mean(mats, axis=0)\n",
    "mat_std = np.std(mats, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-islam",
   "metadata": {},
   "source": [
    "#### Multiplicative noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "searching-accused",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only consider non-zero elements to compute the distribution\n",
    "# of non-zero elements of m_ij / <m_ij>\n",
    "idx = mat_mean > 0.\n",
    "data = []\n",
    "for i in range(len(prefs)):\n",
    "    idxi = mats[i] > 0.\n",
    "    idxi = idx & idxi\n",
    "    data.append(mats[i][idxi] / mat_mean[idxi])\n",
    "data = np.concatenate(data)\n",
    "data = np.sort(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-right",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nbins=2**6\n",
    "nbins='doane'\n",
    "q = 0.00\n",
    "n = len(data)\n",
    "n1 = int(0.5*q*n)\n",
    "n2 = int((1. - 0.5*q)*n)\n",
    "print(f\"n1 = {n1}, n2 = {n2}\")\n",
    "\n",
    "fig = plt.figure(figsize=(4,3), dpi=150)\n",
    "ax = fig.gca()\n",
    "\n",
    "# hist, edges = np.histogram(data[n1:n2], bins=nbins, density=True)\n",
    "hist, edges = np.histogram(np.log(data[n1:n2]), bins=nbins, density=True)\n",
    "\n",
    "print(f\"nbins = \", len(edges)-1)\n",
    "ax.plot(0.5*(edges[:-1]+edges[1:]), hist, '-o', lw=0.5, color='darkblue', ms=2)\n",
    "\n",
    "m = np.mean(np.log(data[n1:n2]))\n",
    "s = np.std(np.log(data[n1:n2]))\n",
    "m,s = scs.norm.fit(np.log(data[n1:n2]), loc=m, scale=s)\n",
    "npts = 1000\n",
    "X = np.linspace(edges[0], edges[-1], npts)\n",
    "Y = 1./ np.sqrt(2.*np.pi*s**2)*np.exp(-0.5*(X-m)**2/s**2)\n",
    "ax.plot(X,Y,'r--',lw=0.5, label=\"$\\\\mu = {:.2f}$\\n$\\sigma = {:.2f}$\".format(m, s))\n",
    "\n",
    "ax.legend(loc='best', fontsize='medium', frameon=False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_xlabel(\"$\\ln{(m_{ij}/\\\\mu_{ij})}$\", fontsize='large')\n",
    "ax.set_ylabel(\"pdf\", fontsize='medium')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selective-armstrong",
   "metadata": {},
   "source": [
    "#### Additive noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-redhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only consider non-zero elements to compute the distribution\n",
    "# of non-zero elements of (m_ij - <m_ij>)/ s_ij\n",
    "idx = mat_std > 0.\n",
    "data = []\n",
    "for i in range(len(prefs)):\n",
    "    idxi = mats[i] > 0.\n",
    "    idxi = idx & idxi\n",
    "    data.append( (mats[i][idxi] - mat_mean[idxi])/mat_std[idxi])\n",
    "data = np.concatenate(data)\n",
    "data = np.sort(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moral-christopher",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nbins=2**6\n",
    "nbins='doane'\n",
    "q = 0.00\n",
    "n = len(data)\n",
    "n1 = int(0.5*q*n)\n",
    "n2 = int((1. - 0.5*q)*n)\n",
    "print(f\"n1 = {n1}, n2 = {n2}\")\n",
    "\n",
    "fig = plt.figure(figsize=(4,3), dpi=150)\n",
    "ax = fig.gca()\n",
    "\n",
    "hist, edges = np.histogram(data[n1:n2], bins=nbins, density=True)\n",
    "# hist, edges = np.histogram(np.log(data[n1:n2]), bins=nbins, density=True)\n",
    "\n",
    "print(f\"nbins = \", len(edges)-1)\n",
    "ax.plot(0.5*(edges[:-1]+edges[1:]), hist, '-o', lw=0.5, color='darkblue', ms=2)\n",
    "\n",
    "# m = np.mean(np.log(data[n1:n2]))\n",
    "# s = np.std(np.log(data[n1:n2]))\n",
    "# m,s = scs.norm.fit(np.log(data[n1:n2]), loc=m, scale=s)\n",
    "# npts = 1000\n",
    "# X = np.linspace(edges[0], edges[-1], npts)\n",
    "# Y = 1./ np.sqrt(2.*np.pi*s**2)*np.exp(-0.5*(X-m)**2/s**2)\n",
    "# ax.plot(X,Y,'r--',lw=0.5, label=\"$\\\\mu = {:.2f}$\\n$\\sigma = {:.2f}$\".format(m, s))\n",
    "\n",
    "ax.legend(loc='best', fontsize='medium', frameon=False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_xlabel(\"$(m_{ij} - \\\\mu_{ij})/\\sigma_{ij}$\", fontsize='large')\n",
    "ax.set_ylabel(\"pdf\", fontsize='medium')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "known-activity",
   "metadata": {},
   "source": [
    "## Compute and show the total fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-soundtrack",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = []\n",
    "data = []\n",
    "count = 0\n",
    "idump = 10\n",
    "for i, pref in enumerate(prefs):\n",
    "    # define all store keys\n",
    "    key_f = \"/fluxes/{:s}\".format(pref)\n",
    "    \n",
    "    if (i%idump == 0):\n",
    "        print(f\"File {i+1} / {len(prefs)}\", key_f)\n",
    "    \n",
    "    t = datetime.datetime.strptime(pref, tfmt)\n",
    "    \n",
    "    with pd.HDFStore(resfile, complevel=complevel, complib=complib) as store:\n",
    "        if not (key_f in store):\n",
    "            print(f\"skipping!\")\n",
    "            continue\n",
    "    \n",
    "        fmat = store[key_f].to_numpy().astype('float64')\n",
    "        \n",
    "    ts.append(t)\n",
    "    fsum = np.sum(fmat)\n",
    "    ftrace = np.einsum('ii', fmat)\n",
    "    data.append([fsum - ftrace, ftrace, float(fsum - ftrace)/ftrace])\n",
    "\n",
    "ts = np.array(ts)\n",
    "data = np.array(data)\n",
    "\n",
    "df_flux_tot = pd.DataFrame(data=data, columns=['flux', 'mobile count', 'relative flux'], index=ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351aabc5-4ce1-46be-af99-c1ca1187b034",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4,3), dpi=150)\n",
    "ax = fig.gca()\n",
    "\n",
    "ax.plot(df_flux_tot.index, df_flux_tot['flux'].to_numpy()/1e6, 'o', ms=2)\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_ylabel(\"total flux (M)\", fontsize='medium')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pregnant-paste",
   "metadata": {},
   "source": [
    "### Analyze the mobile phone count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "declared-contest",
   "metadata": {},
   "outputs": [],
   "source": [
    "idump =10\n",
    "ts = []\n",
    "data = []\n",
    "count = 0\n",
    "for i, pref in enumerate(prefs):\n",
    "    # define all store keys\n",
    "    key_f = \"/fluxes/{:s}\".format(pref)\n",
    "    \n",
    "    if i % idump == 0:\n",
    "        print(f\"File {i+1} / {len(prefs)}\", key_f)\n",
    "    \n",
    "    t = datetime.datetime.strptime(pref, tfmt)\n",
    "    \n",
    "    with pd.HDFStore(resfile, complevel=complevel, complib=complib) as store:\n",
    "        if not (key_f in store):\n",
    "            print(f\"skipping!\")\n",
    "            continue\n",
    "    \n",
    "        fmat = store[key_f].to_numpy().astype('float64')\n",
    "            \n",
    "    pvec = np.einsum('ii->i', fmat)\n",
    "    \n",
    "    ts.append(t)\n",
    "    data.append(pvec)\n",
    "    \n",
    "df_pvec = pd.DataFrame(data=data, columns=clusters.index, index=ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26a09a2-2c54-4351-8f0f-a08bebe59d98",
   "metadata": {},
   "source": [
    "Show the cell phone count per community is approximately constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "burning-beijing",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(df_pvec.index))\n",
    "norm = mco.Normalize(vmin=np.min(indices), vmax=np.max(indices))\n",
    "cmap = cm.rainbow\n",
    "colors = cmap(norm(indices))\n",
    "\n",
    "fig = plt.figure(figsize=(10,2), dpi=300)\n",
    "ax=fig.gca()\n",
    "\n",
    "\n",
    "for i in range(len(indices)):\n",
    "    ax.plot(df_pvec.loc[df_pvec.index[i]], '-', color=colors[i], lw=0.5, ms=0, alpha=0.1)\n",
    "\n",
    "ax.plot(np.diag(fmat_mean), 'k--', lw=0.5)\n",
    "\n",
    "for lab in 'right', 'top':\n",
    "    ax.spines[lab].set_visible(False)\n",
    "ax.tick_params(length=4)\n",
    "ax.set_xlim(0.,None)\n",
    "ax.set_ylim(1,None)\n",
    "ax.set_xlabel('cluster index', fontsize='medium')\n",
    "ax.set_ylabel('# devices', fontsize='medium')\n",
    "ax.set_yscale('log')\n",
    "cax = fig.add_axes(rect=[0.99,0.1,0.01,0.7])\n",
    "cbar = plt.colorbar(cm.ScalarMappable(norm=norm, cmap=cmap),\n",
    "             cax=cax, extendfrac='auto')\n",
    "ticks = cbar.get_ticks()\n",
    "labels = df_pvec.index[ticks.astype('int64')].strftime('%Y-%m-%d').tolist()\n",
    "cbar.set_ticks(ticks)\n",
    "cbar.set_ticklabels(labels)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3145d33-eb20-4e1b-9845-9fc3ade79fcf",
   "metadata": {},
   "source": [
    "Show that the cell phone count is a good proxy for actual population, by comparing the cell phone count with the Census Bureau reported population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leading-english",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_pvec_mean = df_pvec.mean(axis=0)\n",
    "\n",
    "clusters['mobile_count'] = s_pvec_mean\n",
    "key = \"/clustering/clusters\"\n",
    "with pd.HDFStore(resfile, complevel=complevel, complib=complib) as store:\n",
    "    store[key] = clusters\n",
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leading-router",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters.loc[(clusters['population'] == 0) | (clusters['mobile_count'] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rational-sheffield",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pvecT = df_pvec.T\n",
    "\n",
    "indices = np.arange(len(df_pvec.index))\n",
    "norm = mco.Normalize(vmin=np.min(indices), vmax=np.max(indices))\n",
    "cmap = cm.rainbow\n",
    "colors = cmap(norm(indices))\n",
    "\n",
    "ncol = 2\n",
    "fig = plt.figure(facecolor='w', figsize=(8,3), dpi=300)\n",
    "gs = mgs.GridSpec(1, ncol)\n",
    "\n",
    "idx = clusters.index\n",
    "ax1 = fig.add_subplot(gs[0,0])\n",
    "ax2 = fig.add_subplot(gs[0,1])\n",
    "\n",
    "X1 = clusters.loc[idx, 'population'].to_numpy()\n",
    "xsum = np.sum(X1)\n",
    "X2 = X1 / xsum\n",
    "matX1 = []\n",
    "matX2 = []\n",
    "matY1 = []\n",
    "matY2 = []\n",
    "for i in range(len(indices)):\n",
    "    t = df_pvecT.columns[i]\n",
    "    Y1 = df_pvecT.loc[idx,t].to_numpy()\n",
    "    \n",
    "    ax1.plot(X1, Y1, 'o', color=colors[i], lw=0, ms=2, alpha=0.1)\n",
    "    matX1.append(X1)\n",
    "    matY1.append(Y1)\n",
    "    \n",
    "    ysum = np.sum(Y1)\n",
    "    Y2 = Y1 / ysum\n",
    "    ax2.plot(X2, Y2, 'o', color=colors[i], lw=0, ms=2, alpha=0.1)\n",
    "    matX2.append(X2)\n",
    "    matY2.append(Y2)\n",
    "\n",
    "# fits\n",
    "matX1 = np.ravel(matX1)\n",
    "matY1 = np.ravel(matY1)\n",
    "matX2 = np.ravel(matX2)\n",
    "matY2 = np.ravel(matY2)\n",
    "\n",
    "# res = scs.linregress(matX1, matY1)\n",
    "# a1 = res.slope\n",
    "# b1 = res.intercept\n",
    "b1 = 0.\n",
    "a1 = np.sum(matY1) / np.sum(matX1)\n",
    "Xfit = np.array([0., np.max(X1)])\n",
    "ax1.plot(Xfit, a1*Xfit +b1, 'k-', lw=1.)\n",
    "\n",
    "# res = scs.linregress(matX2, matY2)\n",
    "# a2 = res.slope\n",
    "# b2 = res.intercept\n",
    "b2 = 0.\n",
    "a2 = np.sum(matY2) / np.sum(matX2)\n",
    "Xfit = np.array([0., np.max(X2)])\n",
    "ax2.plot(Xfit, a2*Xfit +b2, 'k-', lw=1.)\n",
    "\n",
    "# plot formatting\n",
    "ax1.set_xlabel(\"$M_a$\", fontsize='medium')\n",
    "ax1.set_ylabel(\"$P_a$\", fontsize='medium')\n",
    "ax2.set_xlabel(\"$M_a / \\sum M_a$\", fontsize='medium')\n",
    "ax2.set_ylabel(\"$P_a / \\sum P_a$\", fontsize='medium')\n",
    "for ax in ax1, ax2:\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.tick_params(bottom=True, left=True, labelbottom=True, labelleft=True)\n",
    "    ax.tick_params(length=4)\n",
    "    ax.set_xlim(0., None)\n",
    "    ax.set_ylim(0., None)\n",
    "# ax.set_xlim(0.5, 1.5)\n",
    "# ax.set_ylim(0.5, 1.5)\n",
    "# ax.xaxis.set_major_locator(ticker.MultipleLocator(0.5))\n",
    "# ax.xaxis.set_minor_locator(ticker.MultipleLocator(0.1))\n",
    "# ax.yaxis.set_major_locator(ticker.MultipleLocator(0.5))\n",
    "# ax.yaxis.set_minor_locator(ticker.MultipleLocator(0.1))\n",
    "# ax.set_aspect('equal')\n",
    "        \n",
    "# ax.legend(loc='upper left', fontsize='small', bbox_to_anchor=(1.1, 0.98), frameon=False, ncol=3)\n",
    "    \n",
    "gs.tight_layout(fig, rect=[0.,0.,0.95,1.])\n",
    "cax = fig.add_axes(rect=[0.99,0.2,0.01,0.7])\n",
    "cbar = plt.colorbar(cm.ScalarMappable(norm=norm, cmap=cmap),\n",
    "             cax=cax, extendfrac='auto')\n",
    "ticks = cbar.get_ticks()\n",
    "labels = df_pvec.index[ticks.astype('int64')].strftime('%Y-%m-%d').tolist()\n",
    "cbar.set_ticks(ticks)\n",
    "cbar.set_ticklabels(labels)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
